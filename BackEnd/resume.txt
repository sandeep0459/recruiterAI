HARI SANDEEP REDDY NANDYALA
Buffalo, NY • +1 (716) 705-1836 • [sandeepreddyn08@gmail.com](mailto:sandeepreddyn08@gmail.com) • linkedin.com/in/hari-sandeep-reddy-nandyala • github.com/hari-sandeep-reddy
Professional Summary
I am a Full-Stack Software Engineer with over three years’ experience architecting cloud-native, event-driven microservices and modern frontend applications across fintech, telecom and real-estate domains. I specialise in integrating LLMs and AI workflows using LangChain and OpenAI APIs, building real-time analytics pipelines with Kafka and Redis, and automating CI/CD pipelines for scalable production deployments.
Technical Skills
Languages & Frameworks: Java, Python, Go, TypeScript, JavaScript, SQL
Frontend: React, Next.js, Angular, Tailwind CSS, Material UI, Redux Toolkit, RTK Query
Backend & APIs: Spring Boot, Node.js, Express, gRPC, GraphQL, REST
Data & Streaming: Apache Kafka, Spark, Airflow, PL/SQL, Redis, Hazelcast, MongoDB, PostgreSQL
AI & LLMs: LangChain, LangGraph, OpenAI (GPT-3.5/4), Gemini, FAISS, Pinecone
Cloud & DevOps: AWS (S3, EC2, Lambda), Azure, Kubernetes, Docker, GitHub Actions, Jenkins, Azure DevOps
Testing & Monitoring: JUnit, Mockito, Jasmine/Karma, Prometheus, Grafana
Professional Experience
**PilProgram** | Founding Engineer | Buffalo, NY | Jan 2025 – Present
I lead the development of PARLIAMADE’s full-stack platform, designing a modular React/Next.js portal with Tailwind CSS, Material UI and Firebase Authentication to streamline realtor workflows. On the backend, I built Node.js/Express microservices with MongoDB and Kubernetes orchestration, reducing API latency by 30 %. I engineered a Kafka-driven analytics pipeline with Redis aggregation for sub-second REST endpoints and deployed media storage in AWS S3 with CloudFront caching for low-latency asset delivery.
**Invesco** | Software Engineer | Hyderabad, India | Jan 2022 – Jul 2023
I modernised core investment systems by implementing gRPC transaction handlers in Java/Spring Boot to guarantee atomic fund-reconciliation, cutting end-of-day processing by 25 %. I created a Python microservice using LangChain and OpenAI APIs to automate contract summarisation, saving over 100 manual hours per quarter. I optimised PL/SQL pipelines for portfolio and trade reporting, reducing daily report time by 45 %, and introduced Kafka consumers with Hazelcast IMap caching to drive sub-second dashboard queries. Additionally, I migrated legacy Angular dashboards to React with RTK Query and Material UI, achieving 40 % faster page loads.
**Adroit** | Software Engineer – Backend | Hyderabad, India | Nov 2020 – Dec 2021
I developed standalone Spring Boot microservices to expose ODA reporting metrics via REST, improved data fetching with a GraphQL gateway—cutting redundant calls by 8 %—and built a Spark/Kafka ingestion pipeline to validate and aggregate over one million daily events, slashing downstream processing by 30 %. I also established CI/CD pipelines in Azure DevOps to automate builds, tests and releases, reducing cycle time by 60 %.
Projects
Implementation of Distributed Protocols** | Go, gRPC, Git | Feb 2025
Implemented the Chandy–Lamport global snapshot algorithm and Raft consensus protocol within a Go-based key/value store to capture consistent distributed state, manage leader election, log replication, and ensure fault-tolerant recovery.
**Resume-to-AI Chatbot (RAG Pipeline)** | Python, LangChain, OpenAI API, FAISS, FastAPI, React | May 2025
Engineered a Retrieval-Augmented Generation chatbot by chunking resumes with LangChain, embedding with OpenAI and indexing in FAISS, served through a FastAPI endpoint and a React chat UI, delivering sub-second Q\&A grounded in resume content.
Education
**University at Buffalo, SUNY**
Master of Science in Computer & Information Sciences, GPA 3.7 | Dec 2024


How I built this AI: I built a chatbot using the Retrieval-Augmented Generation (RAG) pipeline to enable context-aware responses grounded in custom documents. I began by loading the relevant documents and splitting them into coherent chunks using `RecursiveCharacterTextSplitter`, which ensures semantic integrity by breaking the text along logical boundaries like paragraphs and sentences. These chunks were then embedded using OpenAI’s `text-embedding-ada-002` model to generate dense vector representations that capture semantic meaning. I stored these vectors in a FAISS (Facebook AI Similarity Search) vector store, which was ideal for this small-scale project due to its in-memory speed and efficient similarity search capabilities. When a user submits a query, the system retrieves the most relevant document chunks from FAISS and passes them, along with the query, to GPT-3.5 Turbo for final answer synthesis. This approach combines precise retrieval with the natural language generation capabilities of the LLM, ensuring the chatbot produces accurate, context-rich responses tailored to the user's input.

If asked anything about how can i replicate this and stuff please elaboarte on the topics which i used to create it and provide a guide.